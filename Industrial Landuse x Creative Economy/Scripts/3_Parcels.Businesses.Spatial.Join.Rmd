---
title: "3_Parcels.Businesses.Spatial.Join"
author: "Brandon Stanaway"
date: "2024-03-28"
output: html_document
---

0.0 Set up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

require(tidyverse)
require(tidycensus)
require(lubridate)
require(stringr)
require(janitor)
require(sf)
require(mapcdatakeys)
require(dplyr)
require(readxl)
#source("C:/Project_Work/Arts_Culture/Industrial Landuse x Creative Economy/Scripts/municipal_name_fix.func.R")

#Load in data keys to add geographies to data later on.
keys <- mapcdatakeys::all_muni_data_keys |> 
  select(
    c(
      muni_name,
      muni_id,
      mapc,
      subrg_acr
    )
  ) |> 
  mutate(
    muni_name = stringr::str_to_title(muni_name)
  )

#Global options to remove scientific notation.
options(scipen = 999)
set.seed(351)

#Set root variables for local data ingestion
#Parcels shapefile
parcels_root <- "C:/Project_Work/Local_Data/Arts_Culture/Industrial_Land_Use/Data/Spatial/"

#Business data 
biz_root <- "C:/Project_Work/Local_Data/Arts_Culture/Industrial_Land_Use/Data/Tabular/intermediary/"

#Set common projecrions + crs for conversion.
mass_mainland<-"+proj=lcc +lat_1=42.68333333333333 +lat_2=41.71666666666667 +lat_0=41 +lon_0=-71.5 +x_0=200000 +y_0=750000 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"
lat_lon_CRS <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
```

1.0 Load relevant data
```{r}
#1.1 Parcels
#Load the parcel polygons
mapc_parcels <- st_read(
  paste0(parcels_root, "LPDB.Dec.23_MAPC.Parcels.shp")
)

#1.2 Businesses
#Load the business data
#Convert business point data to a a spatial object (sf object)
mapc_biz.spatial <- readRDS(
  paste0(biz_root, "DA.23_MAPC.cleaned_waltham.rds")
) |> 
  #Converting the non-spatial data into a spatial object.
  st_as_sf(
    #coords = c("LONGITUDE", "LATITUDE"),
    coords = c("long","lat"),
    crs = st_crs(lat_lon_CRS),
    remove = FALSE
  ) |>
  #Setting CRS to match the polygon's CRS.
  st_transform(
    mass_mainland,
    crs = st_crs(mapc_parcels)
  )
```

2.0 Putting the points into the polygons
```{r}
#Testing that the points are projected similar to the polygons.
#Using Stow as an example because it's small + has only a few points
biz_test <- mapc_biz.spatial |> 
  filter(
    STCITY_CLEAN == "Stow"
  )

parcel_test <- mapc_parcels |> 
  filter(
    CITY == "Stow"
  )

ggplot()+
  geom_sf(data = parcel_test)+
  geom_sf(data = biz_test) +
  theme_minimal()

#Hell yeah - the points are in the polygons!

#Now lets do the point in polygon join for the full dataset
biz_in_parcel <- st_join(mapc_biz.spatial, mapc_parcels, join = st_within)
#parcel_w_biz <- st_join(mapc_parcels, mapc_biz.spatial, join = st_within)
```

2.1 QA/QC SMall Muni Check
```{r}
address_check <- biz_in_parcel |> 
  select(
    Min_LUC,
    CONAME,
    STADDR,
    STCITY_CLEAN,
    LOC_ID,
    ADDR_NUM,
    FULL_STR,
    CITY
  ) |> 
  filter(
    STCITY_CLEAN == "Stow"
  ) |>
  mutate(
    STADDR_NUM = word(STADDR, start = 1, sep = " "),
    addr_num_check = if_else(ADDR_NUM == STADDR_NUM, 1 , 0)
  )

joyleduc_parcel <- mapc_parcels |> 
  filter(
    LOC_ID == "M_201269_909233"
  )

joyleduc_biz <- mapc_biz.spatial |> 
  filter(
    CONAME == "Joy Leduc Photography LLC"
  )

ggplot()+
  geom_sf(data = joyleduc_parcel)+
  geom_sf(data = joyleduc_biz) +
  theme_minimal()

#Multi_address, single loc_id parcels dont have all address information. Make an address match an issue.
#Data Axle does not have full addresses some of the time.
  
```

2.2 Medium Muni Check
```{r}
#Dataset to check address matching
address_check <- biz_in_parcel |> 
  select(
    Min_LUC,
    CONAME,
    STADDR,
    STCITY_CLEAN,
    LOC_ID,
    ADDR_NUM,
    FULL_STR,
    CITY
  ) |> 
  filter(
    STCITY_CLEAN == "Waltham"
  ) |>
  mutate(
    STADDR_NUM = word(STADDR, start = 1, sep = " "),
    addr_num_check = if_else(ADDR_NUM == STADDR_NUM, 1 , 0)
  )

#First Biz
hp_biz <- mapc_biz.spatial |> 
  filter(
    CONAME == "Harvard Printing" & STCITY_CLEAN == "Waltham"
  )

waltham_parcels <- mapc_parcels |> 
  filter(
    CITY == "Waltham" & (FULL_STR == "ELM ST" | FULL_STR == "MOODY ST")
  )

ggplot() +
  geom_sf(data = waltham_parcels, aes(fill = FULL_STR))+
  geom_sf(data = hp_biz) +
  theme_minimal()

#Data axle list this business to be located at 36 Elm Street. The point falls at 362 Moody Street. 
#Data Axle has LAT/LON that do not match the address given in the data.
#FIXED via geocoding!

#Second Biz
rsp_biz <- mapc_biz.spatial |> 
  filter(
    CONAME == "Hajian Architects Inc" & STCITY_CLEAN == "Waltham"
  )

waltham_parcels <- mapc_parcels |> 
  filter(
    CITY == "Waltham" & (FULL_STR == "DEXTER ST" | FULL_STR == "DEXTER AVE")
  )

ggplot() +
  geom_sf(data = waltham_parcels, aes(fill = FULL_STR))+
  geom_sf(data = rsp_biz) +
  theme_minimal()

#Here we have an example of the parcel data not having am address (or parcel) that matches the address of the business (56 Dexter Ave vs 32 Dexter Street). That said, 56 Dexter Ave was geocoded to the appropriate location (no 56 Dexter Ave exists.)
```

3.0 Tabular Analysis
```{r}
#Use codes
Biz_by_LUC <- biz_in_parcel |> 
  group_by(
    Min_LUC
  ) |> 
  summarise(
    Num_Business = n(),
    Employment = sum(LOCEMP),
    Avg
  ) |> 
  ungroup()


Biz_by_LUC_by_NAICS

Biz_by_LUC_Muni
```

4.0 Spatial Analysis
```{r}
#Lets visualize the parcels that do have arts businesses in them

```